---
slug: "/blog/2021-11-21"
date: "2021-11-21"
title: "Micro-frontends, Part 1: Motivation"
tags: "micro-frontends, coding, architecture"
---

In this series, we're going to be walking through (sometimes in painful detail) the micro-frontend architecture that we put in place for
HPE GreenLake Cloud Services. We'll discuss the motivation, architecture, challenges, solutions, and some interesting features that you may want to
consider for your own micro-frontend approach. Let's get started.

## What are micro-frontends?
Before we can double-click on the motivation behind our own shift to an MFE architecture at HPE, we have to first understand what MFEs are. Luckily, our
friend Martin Fowler [has already written an excellent article covering that exact topic](https://martinfowler.com/articles/micro-frontends.html). Please
take the time to read if you're unfamiliar with the concept, as he covers many areas that will be important to understand, moving forward.

## A little context
Historically, Hewlett-Packard (HP) has been a hardware company but [in 2015, HP was split into two companies](https://www.datacenterdynamics.com/en/news/hp-completes-separation-into-two-companies/),
where Hewlett Packard Enterprise (HPE) would now primarily focus on data center and infrastructure services, while HP would continue to provide personal and printing hardware and services.
One of the main goals of HPE right now is the transition to using SaaS for all of its offerings, allowing for a consumption-based model similar to a cloud
provider like AWS.

The realization of this goal requires a drastic shift to the way that HPE has traditionally developed software. Whereas before services were generally installed
on-premise in a "burn it to CD-ROM", manual process that involved a fair amount of hand-holding, services are now accessed directly from a cloud portal. This has two major implications.
First, teams are now responsible for the developer operations and delivery of their service. This means that, in addition to writing the software itself, teams must
own a wide range of peripheral responsibilities, like observability & monitoring, continuous & reliable deployments, security, automation, and all the other things that come
with a DevOps model. And second, teams now must operate in a cloud ecosystem, where the demarcation between services is stark. This means that a team is generally
responsible for the entire stack of a single service, including both front and back end. And HPE has a *lot* of services. Which means a *lot* of teams. Which means
a *lot* of coordination.

Luckily, the model is nothing new and companies have been using the concept of [micro-services](https://martinfowler.com/articles/microservices.html) on the back end for quite some
time to establish context boundaries with clearly defined interfaces between services. But this model is complicated by the front end. There are many companies who still employ a monolithic approach in their front ends, where
service teams all contribute to a single codebase that is built into a single UI. At HPE, we had a setup that was a step above, where services were split into their own repositories and published
as npm packages. Those packages were then composed at build-time in an orchestration layer and deployed as a single bundle. But you still might be able to see the problem here. Despite the fact that back end deployments are
decoupled by using micro-services, if the front end build is still monolithic then you still have a choke point in your software delivery pipeline. Let's say, for example, that one service deploys
code with a runtime error. That runtime error, incorporated by a single team, now will bring down the entire UI if it's not caught during testing. This means that you need to establish a broad, horizontal
set of integration and end-to-end tests that are run anytime a team wants to merge or deploy code! This is **slow**. Furthermore, it's an anti-pattern. And it's something we wanted
to solve in our own architecture at HPE. This gets us to our first goal with micro-frontends.

## Teams should be able to independently promote code
As a service team, I should be solely responsible for the development and delivery of my service area. Team X should not have their pipeline slowed down because Team Y needs
to run an extensive suite of tests. By segmenting our deployments into smaller pieces, we accomplish the following things:

* deployments are faster by only testing things that the service needs to test
* continuous deployment of services is not gated by the concerns of neighbors
* deployments to lower environments (like QA) can be managed per team

In addition to releasing independently, we also want to provide a completely orthogonal development experience for each service. This is our second goal.

## Teams should be able to independently develop code
By partitioning the development process across services, a number of process-related benefits can be reaped. Each team is solely responsible for a
repository (or set of repositories), which gives them full control over their development lifecycle. When these processes are separate for each team, we observe
teams whose sole focus is the development of their services, without distractions from other teams. Some benefits include:

* teams can independently determine their branching strategies
* teams can apply root configurations that are catered to the needs their service
* teams can easily view and understand development metrics
* teams own access management to repositories under their purview

For more information on the benefits of independent development for teams, see [this explanation](https://github.com/joelparkerhenderson/monorepo-vs-polyrepo). Note that
while this compares monorepos to polyrepos, many of the ideas parallel those used to think about combined versus independent processes.

## Teams should be technology-agnostic
In the original build-time approach to our UI at HPE, every team had to write their services in React. But this doesn't always make sense. React is great for larger, dynamic web
applications, but what if you have the need to incorporate pre-client data transformations in your service that a framework like Svelte is better catered for? What if your app doesn't have any dynamic data - like a documentation portal
that would be more suited to a static-site approach? What if your developers aren't familiar with React? What if your service is coming from an acquisition that was
written in Vue? You can see that we have all these use cases where strictly enforcing React as Our Language is going to cause problems. And problems, we had. The Consumption Analytics
service serves as a good example. This service came from an acquired company called Cloud Cruiser, and their entire application was written in Angular. So on
day one, what do you think they were doing? Re-writing their app in React. This was a *massive* waste of resources and certainly cost the company hundreds of thousands, if not
millions of dollars, in developer effort. By forcing teams to all use the same framework, you run into the following issues:

* teams are unable to choose the right tools for their use case
* newly acquired services need to be re-written in the common framework
* all developers need to master a single framework
* the application is prone to vendor lock-in
* teams are unable to innovate and experiment with new technologies

By allowing teams to have agnostic stacks, they can choose the right tool for the job, depending on the use case for their particular service.

## Teams should not have to share dependencies

There are other issues with tying together services at build-time. Recall that all the dependencies for an app are compiled at build-time. This means that services have
to share dependencies that they both rely on. Many of these dependencies have "singleton-type functionality" where a single static instance is established or a field is placed
on the global scope. If two services are using a different version of the same package, then it will often cause conflicts. This means the following things:

* teams need to coordinate what versions of what dependencies are used
* resolutions need to be set for certain packages
* teams will run into tricky bugs due to having two versions of a dependency
* requires a central authority to federate what dependencies are used
* upgrading of dependencies requires lock-step upgrades across all services

## Nothing comes for free

We can now see that all of these things support a core principal that **services should not be affected by other services**. It should also be noted that all of these approaches
have trade-offs. Remember, that in software everything is a trade-off; nothing comes for free. For example, by being framework-agnostic it becomes much more difficult to enforce
consistency between apps with a common set of componentry. We'll discuss some of these downsides in more detail in coming articles. But in our experience, these trade-offs have
been well worth it so far, as the alternatives are far more pernicious.

So, how do we accomplish these things? The answer generally revolves around the move from a build-time to run-time approach for service composition, which is one of the
major benefits of an MFE-based architecture. In the next article, we'll discuss the high-level architecture and the core technologies that we used to implement
our MFE at HPE.
